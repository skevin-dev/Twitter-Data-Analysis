{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214619b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "def read_json(json_file: str)->list:\n",
    "    \"\"\"\n",
    "    json file reader to open and read json files into a list\n",
    "    Args:\n",
    "    -----\n",
    "    json_file: str - path of a json file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    length of the json file and a list of json\n",
    "    \"\"\"\n",
    "    \n",
    "    tweets_data = []\n",
    "    for tweets in open(json_file,'r'):\n",
    "        tweets_data.append(json.loads(tweets))\n",
    "    \n",
    "    \n",
    "    return len(tweets_data), tweets_data\n",
    "\n",
    "class TweetDfExtractor:\n",
    "    \"\"\"\n",
    "    this function will parse tweets json into a pandas dataframe\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    dataframe\n",
    "    \"\"\"\n",
    "    def __init__(self, tweets_list):\n",
    "        \n",
    "        self.tweets_list = tweets_list\n",
    "\n",
    "    # an example function\n",
    "    def find_statuses_count(self)->list:\n",
    "        #create an empty list \n",
    "        statuses_count = list()\n",
    "        \n",
    "        #iterate through tweets list \n",
    "        for x in self.tweets_list:\n",
    "            #append in created list statuses count\n",
    "            statuses_count.append(x['user']['statuses_count'])\n",
    "                                  \n",
    "    def find_full_text(self)->list:\n",
    "        \n",
    "        # create an empty list\n",
    "        text = []\n",
    "        for tweets in self.tweets_list:\n",
    "            if \"retweeted_status\" in [keys for keys,values in tweets.items()] and \"extended_tweet\" in tweets['retweeted_status'].keys():\n",
    "                text.append(tweets['retweeted_status']['extended_tweet']['full_text'])\n",
    "            else:\n",
    "                text.append(\"Empty\")\n",
    "        return text\n",
    "                                  \n",
    "         \n",
    "    def find_sentiments(self, text)->list:\n",
    "        polarity = []\n",
    "        subjectivity = []\n",
    "        for tweets in text:\n",
    "            blob = TextBlob(tweets)\n",
    "            sentiment = blob.sentiment\n",
    "            polarity.append(sentiment.polarity)\n",
    "            subjectivity.append(sentiment.subjectivity)\n",
    "        return polarity, subjectivity\n",
    "\n",
    "    def find_created_time(self)->list:\n",
    "        created_at = []\n",
    "        for x in self.tweets_list:\n",
    "            created_at.append(x['created_at'])\n",
    "       \n",
    "        return created_at\n",
    "\n",
    "    def find_source(self)->list:\n",
    "        # I can also use list comprehensiom\n",
    "        source = [x['source'] for x in self.tweets_list]\n",
    "\n",
    "        return source\n",
    "\n",
    "    def find_screen_name(self)->list:\n",
    "        screen_name = []\n",
    "        for x in self.tweets_list:\n",
    "            screen_name.append(x['user']['screen_name']) \n",
    "        return screen_name\n",
    "                                  \n",
    "    def find_followers_count(self)->list:\n",
    "        followers_count =[]\n",
    "        for x in self.tweets_list:\n",
    "            followers_count.append(x['user']['followers_count'])\n",
    "        return followers_count\n",
    "\n",
    "    def find_friends_count(self)->list:\n",
    "        friends_count= []\n",
    "        for x in self.tweets_list:\n",
    "            friends_count.append(x['user']['friends_count'])\n",
    "        return friends_count\n",
    "\n",
    "    def is_sensitive(self)->list:\n",
    "        try:\n",
    "            is_sensitive = []\n",
    "            for tweets in self.tweets_list:\n",
    "                if 'possibly_sensitive' in [keys for keys,values in tweets.items()]:\n",
    "                    is_sensitive.append(tweets['possibly_sensitive'])\n",
    "                else:\n",
    "                    is_sensitive.append(0)\n",
    "                    \n",
    "        except KeyError:\n",
    "            is_sensitive = None\n",
    "\n",
    "        return is_sensitive\n",
    "\n",
    "    def find_favourite_count(self)->list:\n",
    "        favorite_count = list()\n",
    "        for tweets in self.tweets_list:\n",
    "            if 'retweeted_status' in [keys for keys,values in tweets.items()]:\n",
    "                favorite_count.append(tweets['retweeted_status']['favorite_count'])\n",
    "            else:\n",
    "                favorite_count.append(0)\n",
    "        return favorite_count\n",
    "        \n",
    "    \n",
    "    def find_retweet_count(self)->list:\n",
    "        retweet_count = list()\n",
    "        for tweets in self.tweets_list:\n",
    "            if 'retweeted_status' in [keys for keys,values in tweets.items()]:\n",
    "                retweet_count.append(tweets['retweeted_status']['retweet_count'])\n",
    "            else:\n",
    "                retweet_count.append(0)\n",
    "        return retweet_count\n",
    "\n",
    "    def find_hashtags(self)->list:\n",
    "        hashtags = []\n",
    "\n",
    "        for tweets in self.tweets_list:\n",
    "            hashtags.append(\",\".join([x['text'] for x in tweets['entities']['hashtags']]))\n",
    "        return hashtags\n",
    "\n",
    "    def find_mentions(self)->list:\n",
    "        mentions = []\n",
    "        for tweets in self.tweets_list:\n",
    "            mentions.append( \", \".join([x['screen_name'] for x in tweets['entities']['user_mentions']]))\n",
    "\n",
    "        return mentions\n",
    "                                  \n",
    "\n",
    "\n",
    "    def find_location(self)->list:\n",
    "        try:\n",
    "            location = self.tweets_list['user']['location']\n",
    "        except TypeError:\n",
    "            location = ''\n",
    "        \n",
    "        return location\n",
    "\n",
    "    def find_lang(self)->list:\n",
    "        lang = []\n",
    "        for x in self.tweets_list:\n",
    "            lang.append(x['lang'])\n",
    "        return lang\n",
    "        \n",
    "        \n",
    "    def get_tweet_df(self, save=False)->pd.DataFrame:\n",
    "        \"\"\"required column to be generated you should be creative and add more features\"\"\"\n",
    "        \n",
    "        columns = ['created_at', 'source', 'original_text','polarity','subjectivity', 'lang', 'favorite_count', 'retweet_count', \n",
    "            'original_author', 'followers_count','friends_count','possibly_sensitive', 'hashtags', 'user_mentions', 'place']\n",
    "        \n",
    "        created_at = self.find_created_time()\n",
    "        source = self.find_source()\n",
    "        text = self.find_full_text()\n",
    "        polarity, subjectivity = self.find_sentiments(text)\n",
    "        lang = self.find_lang()\n",
    "        fav_count = self.find_favourite_count()\n",
    "        retweet_count = self.find_retweet_count()\n",
    "        screen_name = self.find_screen_name()\n",
    "        follower_count = self.find_followers_count()\n",
    "        friends_count = self.find_friends_count()\n",
    "        sensitivity = self.is_sensitive()\n",
    "        hashtags = self.find_hashtags()\n",
    "        mentions = self.find_mentions()\n",
    "        location = self.find_location()\n",
    "        data = {\"created_at\":created_at,'source':source,'original_text':text,'polarity':polarity,'subjectivity':subjectivity,\n",
    "                'lang':lang,'favorite_count':fav_count,'retweet_count':retweet_count,'original_author':screen_name, \n",
    "                'followers_count':follower_count,'friends_count':friends_count,'possibly_sensitive':sensitivity,\n",
    "                'hashtags':hashtags,'user_mentions':mentions}\n",
    "\n",
    "#         data = zip(created_at, source, text, polarity, subjectivity, lang, fav_count, retweet_count, screen_name, follower_count, friends_count, sensitivity, hashtags, mentions, location)\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "        if save:\n",
    "            df.to_csv('processed_tweet_data.csv', index=False)\n",
    "            print('File Successfully Saved.!!!')\n",
    "        \n",
    "        return df\n",
    "\n",
    "                \n",
    "if __name__ == \"__main__\":\n",
    "    # required column to be generated you should be creative and add more features\n",
    "    columns = ['created_at', 'source', 'original_text','clean_text', 'sentiment','polarity','subjectivity', 'lang', 'favorite_count', 'retweet_count', \n",
    "    'original_author', 'screen_count', 'followers_count','friends_count','possibly_sensitive', 'hashtags', 'user_mentions', 'place', 'place_coord_boundaries']\n",
    "    _, tweet_list = read_json(\"Economic_Twitter_Data.json\")\n",
    "    tweet = TweetDfExtractor(tweet_list)\n",
    "    tweet_df = tweet.get_tweet_df() \n",
    "\n",
    "    # use all defined functions to generate a dataframe with the specified columns above\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad6a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clean_Tweets:\n",
    "    \"\"\"\n",
    "    The PEP8 Standard AMAZING!!!\n",
    "    \"\"\"\n",
    "    def __init__(self, df:pd.DataFrame):\n",
    "        self.df = df\n",
    "        print('Automation in Action...!!!')\n",
    "        \n",
    "    def drop_unwanted_column(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        remove rows that has column names. This error originated from\n",
    "        the data collection stage.  \n",
    "        \"\"\"\n",
    "        unwanted_rows = df[df['retweet_count'] == 'retweet_count' ].index\n",
    "        df.drop(unwanted_rows , inplace=True)\n",
    "        df = df[df['polarity'] != 'polarity']\n",
    "        \n",
    "        return df\n",
    "    def drop_duplicate(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        drop duplicate rows\n",
    "        \"\"\"\n",
    "        self.df = self.df.drop_duplicates().drop_duplicates(subset='original_text')\n",
    "        \n",
    "        return df\n",
    "    def convert_to_datetime(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        convert column to datetime\n",
    "        \"\"\"\n",
    "        self.df['created_at'] = pd.to_datetime(self.df['created_at'], errors='coerce')\n",
    "        \n",
    "        df = df[df['created_at'] >= '2020-12-31' ]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def convert_to_numbers(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        convert columns like polarity, subjectivity, retweet_count\n",
    "        favorite_count etc to numbers\n",
    "        \"\"\"\n",
    "        \n",
    "        # convert polarity column to numeric, coerce for setting Invalid parsing to nan\n",
    "        df['polarity'] = pd.to_numeric(self.df['polarity'],errors=\"ignore\")\n",
    "        \n",
    "        # same applies to other column\n",
    "        df['subjectivity'] = pd.to_numeric(self.df['subjectivity'], errors=\"ignore\")\n",
    "        \n",
    "        # putting square bracket while extracting column is the same putting a dot \n",
    "        df['favorite_count'] = pd.to_numeric( self.df.favorite_count, errors= \"ignore\")\n",
    "        \n",
    "        df['retweet_count'] = pd.to_numeric(self.df.retweet_count, errors=\"ignore\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def remove_non_english_tweets(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        remove non english tweets from lang\n",
    "        \"\"\"\n",
    "        # we use query function to query tweets whereby lang(language) = en(english)\n",
    "        df = self.df.query(\"lang == 'en'\")\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a617b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Clean_Tweets(tweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1177da61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = r.remove_non_english_tweets(tweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a1265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b438314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['created_at'] >= '2020-12-31' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6037e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polarity'] = pd.to_numeric(df['polarity'],errors=\"ignore\")\n",
    "        \n",
    "# same applies to other column\n",
    "df['subjectivity'] = pd.to_numeric(df['subjectivity'], errors=\"ignore\")\n",
    "\n",
    "# putting square bracket while extracting column is the same putting a dot \n",
    "df['favorite_count'] = pd.to_numeric( df.favorite_count, errors= \"ignore\")\n",
    "\n",
    "df['retweet_count'] = pd.to_numeric(df.retweet_count, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d3745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aee1014",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509bfc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb035509",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.iloc[2:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502823bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(b, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1a35dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['user_mentions'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1e34b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8804b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"place\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ba848",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "length = []\n",
    "for i in df.columns:\n",
    "    columns.append(i)\n",
    "    length.append(len(df[i].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bcb8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_={}\n",
    "r = []\n",
    "for i,j in zip(columns,length):\n",
    "    dict_[i] = j\n",
    "    r.append(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ = r[0]\n",
    "r_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfe61d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame(r_,index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627c1934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "r.plot(kind=\"bar\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5),ncol=2)\n",
    "plt.title(\"unique values for each column\",fontweight=\"bold\")\n",
    "plt.xlabel(\"columns\")\n",
    "plt.ylabel(\"unique values\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b05827",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['favorite_count'],df['retweet_count'])\n",
    "plt.title(\"favorite count against retweet count\")\n",
    "plt.xlabel(\"favorite count\")\n",
    "plt.ylabel(\"retweet count\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be3d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df['hashtags'] = df['hashtags'].replace('',np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee21d702",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(df['hashtags'].unique())\n",
    "a.remove(np.NaN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b121d955",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = []\n",
    "values = []\n",
    "for i in a:\n",
    "    a = df[df['hashtags']==i]\n",
    "    hashtags.append(i)\n",
    "    values.append(len(a))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "D = {}\n",
    "for i,j in zip(hashtags,values):\n",
    "    D[i] = j\n",
    "    d.append(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c3208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8888a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_orders = sorted(w.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd4bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = []\n",
    "t = []\n",
    "for i in sort_orders:\n",
    "    e.append(i[0])\n",
    "    t.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bfae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61da2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(e[0:10],t[0:10])\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"hashtags\")\n",
    "plt.title(\"top 10 hashtags\",fontweight=\"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25551a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = list(df['original_author'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd420c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = []\n",
    "values_auth = []\n",
    "for i in v:\n",
    "    a = df[df['original_author']==i]\n",
    "    authors.append(i)\n",
    "    values_auth.append(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e3d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = []\n",
    "t = {}\n",
    "for i,j in zip(authors,values_auth):\n",
    "    t[i] = j\n",
    "    p.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b4cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_orders_ = sorted(p[0].items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895131d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = []\n",
    "n = []\n",
    "for i in sort_orders_:\n",
    "    m.append(i[0])\n",
    "    n.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c1bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(m[0:10],n[0:10])\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"original author\")\n",
    "plt.title(\"Top 10 authors\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec7613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
